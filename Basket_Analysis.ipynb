{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1756357721168,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "D04FoYolEI8l"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Retail Basket Analysis (PySpark)\n",
    "# End-to-end pipeline: load → clean → baskets → FPGrowth → rules → recs → export\n",
    "# =========================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1756357905186,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "BKXqqF5fEYhf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Parameters (tune here) ----------\n",
    "INPUT_PATH = \"A:\\My project\\Retail Analyitcs\\Data\\Retail_pos_basket_data.csv.csv\"\n",
    "OUTPUT_DIR = \"/content/ouput\"   # will be created if not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756357909194,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "s5NKlADEEbaf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Keep items that appear at least this many times before mining\n",
    "MIN_ITEM_FREQ = 10                         # raise/lower based on dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756357911645,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "zjf8ohgGEewo"
   },
   "outputs": [],
   "source": [
    "# If you prefer absolute min-support (e.g., 0.02 means 2% of baskets), leave as number in (0,1].\n",
    "# If you prefer absolute count, set MIN_SUPPORT_ABS > 1 and we'll convert to relative later.\n",
    "MIN_SUPPORT_REL = 0.02\n",
    "MIN_SUPPORT_ABS = None                     # e.g., 50 (overrides MIN_SUPPORT_REL if set)\n",
    "\n",
    "MIN_CONFIDENCE = 0.3\n",
    "TOP_K_RULES = 200                          # for quick inspection/exports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7702,
     "status": "ok",
     "timestamp": 1756357921577,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "rags46VoEh4h"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Start Spark ----------\n",
    "spark = SparkSession.builder.appName(\"Retail Basket Analysis - PySpark\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 9224,
     "status": "ok",
     "timestamp": 1756357933037,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "aRmYuiV1Ej-c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ---------- Load ----------\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(INPUT_PATH, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Load ----------\n",
    "df_raw = spark.read.csv(INPUT_PATH, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1756357937424,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "01s4VzX1El4g"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make column names uniform\n",
    "df = df_raw.select([F.col(c).alias(c.strip().lower()) for c in df_raw.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756357940730,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "aSqR1OA5EoWt"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Try to auto-detect transaction and item columns\n",
    "txn_candidates = [\"transactionid\",\"transaction_id\",\"invoice\",\"invoice_no\",\"bill_no\",\n",
    "                  \"order_id\",\"orderid\",\"basket_id\",\"txn_id\",\"receipt_id\",\"sale_id\",\"ticket_no\",\"trans_id\"]\n",
    "item_candidates = [\"item\",\"item_name\",\"product\",\"product_name\",\"sku\",\"description\",\"prod\",\"name\"]\n",
    "\n",
    "def pick_col(candidates, cols):\n",
    "    s = set(cols)\n",
    "    for c in candidates:\n",
    "        if c in s:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "txn_col = pick_col(txn_candidates, df.columns)\n",
    "item_col = pick_col(item_candidates, df.columns)\n",
    "\n",
    "if txn_col is None or item_col is None:\n",
    "    raise ValueError(f\"Could not auto-detect required columns. \"\n",
    "                     f\"Found columns: {df.columns}. \"\n",
    "                     f\"Please rename your transaction column to one of {txn_candidates} \"\n",
    "                     f\"and item column to one of {item_candidates}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1756357946799,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "YqDVK30YEqD_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Optional helpers (if present)\n",
    "qty_col = pick_col([\"quantity\",\"qty\",\"count\"], df.columns)\n",
    "price_col = pick_col([\"price\",\"amount\",\"unit_price\",\"mrp\",\"rate\"], df.columns)\n",
    "cat_col = pick_col([\"category\",\"product_category\",\"cat\"], df.columns)\n",
    "brand_col = pick_col([\"brand\"], df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1756357949940,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "2iOMdk1cErh9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------- Clean items ----------\n",
    "# Normalize item strings: trim, lower, collapse spaces\n",
    "norm = F.udf(lambda s: \" \".join(s.strip().split()).lower() if s is not None else None, T.StringType())\n",
    "\n",
    "df_clean = (\n",
    "    df\n",
    "    .withColumn(item_col, norm(F.col(item_col).cast(\"string\")))\n",
    "    .withColumn(txn_col, F.col(txn_col).cast(\"string\"))\n",
    "    .filter(F.col(item_col).isNotNull() & (F.length(F.col(item_col)) > 0))\n",
    "    .filter(F.col(txn_col).isNotNull() & (F.length(F.col(txn_col)) > 0))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756357951887,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "PcOsOmVEEs4H"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Optional: drop obvious noise like \"na\", \"misc\", etc. ----------\n",
    "noise = [\"na\",\"n/a\",\"none\",\"misc\",\"unknown\"]\n",
    "df_clean = df_clean.filter(~F.col(item_col).isin(noise))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1756357953951,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "p1VmkgVREuZ2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Filter very rare items to reduce noise & speed up ----------\n",
    "item_freq = (\n",
    "    df_clean.groupBy(item_col)\n",
    "            .agg(F.countDistinct(txn_col).alias(\"txn_count\"))\n",
    ")\n",
    "\n",
    "df_items_kept = item_freq.filter(F.col(\"txn_count\") >= F.lit(MIN_ITEM_FREQ))\n",
    "df_clean = df_clean.join(df_items_kept.select(item_col), on=item_col, how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5776,
     "status": "ok",
     "timestamp": 1756357961257,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "sCZGYL-KEvoV",
    "outputId": "9d467cf9-c037-4f97-bf83-e91ee8a56ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total baskets: 1991\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Build baskets (set not list to avoid duplicates in same txn) ----------\n",
    "baskets = (\n",
    "    df_clean.groupBy(txn_col)\n",
    "            .agg(F.collect_set(F.col(item_col)).alias(\"items\"))\n",
    "            .filter(F.size(F.col(\"items\")) >= 2)  # baskets of at least 2 items\n",
    ")\n",
    "\n",
    "num_txns = baskets.count()\n",
    "print(f\"Total baskets: {num_txns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1756357963892,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "aiE8TMNiExNV",
    "outputId": "5dc4463b-5bf7-42c4-9768-7f95bfe9358f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using minSupport=0.02000, minConfidence=0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Compute minSupport ----------\n",
    "if MIN_SUPPORT_ABS is not None and MIN_SUPPORT_ABS > 1:\n",
    "    min_support = float(MIN_SUPPORT_ABS) / max(1, num_txns)\n",
    "else:\n",
    "    min_support = float(MIN_SUPPORT_REL)\n",
    "\n",
    "print(f\"Using minSupport={min_support:.5f}, minConfidence={MIN_CONFIDENCE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5547,
     "status": "ok",
     "timestamp": 1756357973004,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "exP1NaEnEyjG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Mine frequent itemsets & rules via FPGrowth ----------\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "fp = FPGrowth(itemsCol=\"items\", minSupport=min_support, minConfidence=MIN_CONFIDENCE)\n",
    "model = fp.fit(baskets)\n",
    "\n",
    "freq_itemsets = model.freqItemsets  # columns: items (array<string>), freq (long)\n",
    "rules = model.associationRules      # columns: antecedent, consequent, confidence, lift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756357975340,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "YtGlsrlVE0Ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Post-process rules ----------\n",
    "rules_enh = (\n",
    "    rules\n",
    "    .withColumn(\"ante_len\", F.size(\"antecedent\"))\n",
    "    .withColumn(\"cons_len\", F.size(\"consequent\"))\n",
    "    .withColumn(\"rule_str\",\n",
    "        F.concat(F.array_join(F.col(\"antecedent\"), \", \"),\n",
    "                 F.lit(\" -> \"),\n",
    "                 F.array_join(F.col(\"consequent\"), \", \"))\n",
    "    )\n",
    "    .orderBy(F.col(\"lift\").desc(), F.col(\"confidence\").desc())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756357977886,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "g2E3Hl53E1ZG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Stronger rule slice for business (tune thresholds if needed)\n",
    "rules_strong = rules_enh.filter(\n",
    "    (F.col(\"confidence\") >= F.lit(MIN_CONFIDENCE)) & (F.col(\"lift\") > 1.0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1756357979703,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "8lM1nPVqE2h7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Item → item top-N recommendations ----------\n",
    "# explode antecedent to get \"seed item\" → recommended consequents\n",
    "exploded = (\n",
    "    rules_strong\n",
    "    .withColumn(\"seed\", F.explode(\"antecedent\"))\n",
    "    .withColumn(\"rec\", F.explode(\"consequent\"))\n",
    "    .select(\"seed\",\"rec\",\"confidence\",\"lift\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1756358001162,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "A12Btt0OE3_8"
   },
   "outputs": [],
   "source": [
    "# Rank recs per seed item\n",
    "# window = F.window.partitionBy(\"seed\").orderBy(F.col(\"lift\").desc(), F.col(\"confidence\").desc())\n",
    "# Note: Spark SQL Window is in pyspark.sql.window.Window (not F.window)\n",
    "from pyspark.sql.window import Window\n",
    "win = Window.partitionBy(\"seed\").orderBy(F.col(\"lift\").desc(), F.col(\"confidence\").desc())\n",
    "\n",
    "item_recs = (\n",
    "    exploded\n",
    "    .withColumn(\"rank\", F.row_number().over(win))\n",
    "    .filter(F.col(\"rank\") <= 5)  # top-5 per item\n",
    "    .orderBy(\"seed\",\"rank\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4041,
     "status": "ok",
     "timestamp": 1756358015045,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "zlfjQgzGE5bq",
    "outputId": "cfbce950-55ad-48f7-b4fb-4fef4df776a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept items >= 10 txn: 68\n",
      "All rules: 0\n",
      "Strong rules (conf>=0.3, lift>1): 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Quick KPIs ----------\n",
    "total_items = df_items_kept.count()\n",
    "total_rules = rules.count()\n",
    "strong_rules_cnt = rules_strong.count()\n",
    "\n",
    "print(f\"Kept items >= {MIN_ITEM_FREQ} txn: {total_items}\")\n",
    "print(f\"All rules: {total_rules}\")\n",
    "print(f\"Strong rules (conf>={MIN_CONFIDENCE}, lift>1): {strong_rules_cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2110,
     "status": "ok",
     "timestamp": 1756358084158,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "vVYjPUKiEM0_"
   },
   "outputs": [],
   "source": [
    "# ---------- Save outputs ----------\n",
    "\n",
    "# Order freq_itemsets BEFORE converting array column to string\n",
    "freq_itemsets_ordered = (\n",
    "    freq_itemsets\n",
    "    .orderBy(F.size(\"items\").desc(), F.col(\"freq\").desc())\n",
    "    .limit(5000)\n",
    ")\n",
    "\n",
    "# Convert array columns to strings before writing to CSV\n",
    "freq_itemsets_csv = freq_itemsets_ordered.withColumn(\"items\", F.array_join(\"items\", \", \"))\n",
    "rules_enh_csv = rules_enh.withColumn(\"antecedent\", F.array_join(\"antecedent\", \", \")).withColumn(\"consequent\", F.array_join(\"consequent\", \", \"))\n",
    "rules_strong_csv = rules_strong.withColumn(\"antecedent\", F.array_join(\"antecedent\", \", \")).withColumn(\"consequent\", F.array_join(\"consequent\", \", \"))\n",
    "item_recs_csv = item_recs # item_recs doesn't have array columns\n",
    "\n",
    "(\n",
    "    freq_itemsets_csv\n",
    "    .coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"header\", True)\n",
    "    .csv(f\"{OUTPUT_DIR}/freq_itemsets\")\n",
    ")\n",
    "\n",
    "(\n",
    "    rules_enh_csv\n",
    "    .limit(TOP_K_RULES)\n",
    "    .coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"header\", True)\n",
    "    .csv(f\"{OUTPUT_DIR}/association_rules_top\")\n",
    ")\n",
    "\n",
    "(\n",
    "    rules_strong_csv\n",
    "    .limit(TOP_K_RULES)\n",
    "    .coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"header\", True)\n",
    "    .csv(f\"{OUTPUT_DIR}/association_rules_strong_top\")\n",
    ")\n",
    "\n",
    "# The item_recs DataFrame does not contain array columns, so it can be written directly\n",
    "(\n",
    "    item_recs_csv\n",
    "    .coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"header\", True)\n",
    "    .csv(f\"{OUTPUT_DIR}/item_recommendations_top5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5238,
     "status": "ok",
     "timestamp": 1756358096666,
     "user": {
      "displayName": "ARUNAGIRINATHAN K",
      "userId": "02800238563457290768"
     },
     "user_tz": -330
    },
    "id": "_EFh5ClKEXiz",
    "outputId": "144b38d7-d3d8-4479-a4d3-590bd5387039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top frequent itemsets ===\n",
      "+--------------------+----+\n",
      "|items               |freq|\n",
      "+--------------------+----+\n",
      "|[dishwashing liquid]|163 |\n",
      "|[chips]             |161 |\n",
      "|[cake]              |158 |\n",
      "|[energy drink]      |158 |\n",
      "|[soda]              |158 |\n",
      "|[prawns]            |157 |\n",
      "|[tissue]            |157 |\n",
      "|[phone cover]       |156 |\n",
      "|[milk]              |155 |\n",
      "|[toilet paper]      |154 |\n",
      "|[salt]              |154 |\n",
      "|[face wash]         |154 |\n",
      "|[spinach]           |154 |\n",
      "|[pasta]             |153 |\n",
      "|[shoes]             |152 |\n",
      "+--------------------+----+\n",
      "only showing top 15 rows\n",
      "\n",
      "\n",
      "=== Top rules by lift/confidence ===\n",
      "+--------+----------+----+\n",
      "|rule_str|confidence|lift|\n",
      "+--------+----------+----+\n",
      "+--------+----------+----+\n",
      "\n",
      "\n",
      "=== Item → Top-5 recommendations (by lift/conf) ===\n",
      "+----+---+----------+----+----+\n",
      "|seed|rec|confidence|lift|rank|\n",
      "+----+---+----------+----+----+\n",
      "+----+---+----------+----+----+\n",
      "\n",
      "\n",
      "Prediction coverage on historical baskets: 0.00%\n",
      "\n",
      "✅ Done. Outputs written under: /content/ouput\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Optional: quick inspection in console ----------\n",
    "print(\"\\n=== Top frequent itemsets ===\")\n",
    "freq_itemsets.orderBy(F.col(\"freq\").desc()).show(15, truncate=False)\n",
    "\n",
    "print(\"\\n=== Top rules by lift/confidence ===\")\n",
    "rules_enh.select(\"rule_str\",\"confidence\",\"lift\").show(15, truncate=False)\n",
    "\n",
    "print(\"\\n=== Item → Top-5 recommendations (by lift/conf) ===\")\n",
    "item_recs.show(30, truncate=False)\n",
    "\n",
    "# ---------- (Optional) Coverage of prediction on known baskets ----------\n",
    "predicted = model.transform(baskets)  # adds \"prediction\" column\n",
    "coverage = predicted.filter(F.size(\"prediction\") > 0).count() / float(num_txns) if num_txns else 0.0\n",
    "print(f\"\\nPrediction coverage on historical baskets: {coverage:.2%}\")\n",
    "\n",
    "print(f\"\\n✅ Done. Outputs written under: {OUTPUT_DIR}\")\n",
    "\n",
    "# spark.stop()  # uncomment if you want Spark to close here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPBCJYvglFzMaiR282wJ5dO",
   "mount_file_id": "1XSiNlREGu4xtnqHaWRGVVtcWpn1_TW2B",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
